### 限流算法

高并发系统设计的3个利器：缓存、限流、降级。

从分布式角度来看，限流可分为**分布式限流**（比如基于Sentinel或者Redis的集群限流）和**单机限流**。从算法实现角度来看，限流算法可分为**漏桶算法**、**令牌桶算法**和**滑动时间窗口算法**。下面主要分析这3种限流算法和分布式限流实现方案。

#### 计数器算法

计数器限流算法也是比较常用的，主要用来限制总并发数，比如数据库连接池大小、线程池大小、程序访问并发数等都是使用计数器算法。

1. 采用AtomicInteger

   使用AomicInteger来进行统计当前正在并发执行的次数，如果超过域值就简单粗暴的直接响应给用户，说明系统繁忙，请稍后再试或其它跟业务相关的信息。

   弊端：使用 AomicInteger 简单粗暴超过域值就拒绝请求，可能只是瞬时的请求量高，也会拒绝请求。

2. 采用令牌Semaphore

   使用Semaphore信号量来控制并发执行的次数，如果超过域值信号量，则进入阻塞队列中排队等待获取信号量进行执行。如果阻塞队列中排队的请求过多超出系统处理能力，则可以在拒绝请求。

   相对Atomic优点：如果是瞬时的高并发，可以使请求在阻塞队列中排队，而不是马上拒绝请求，从而达到一个流量削峰的目的。

3. 采用ThreadPoolExecutor java线程池

   固定线程池大小,超出固定先线程池和最大的线程数,拒绝线程请求;

#### 漏桶算法（Token Bucket）

一个固定容量的漏桶，按照常量固定速率流出水滴。漏桶算法思路很简单，请求先进入到漏桶里，漏桶以固定的速度出水，也就是处理请求，当水加的过快，则会直接溢出，也就是拒绝请求，可以看出漏桶算法能强行限制数据的传输速率。

- 漏桶实现点

  - 定义一个桶的容量
  - 记录上一次桶的刷新时间和水量，以便后续计算当前桶里的水
  - 定义水的流出速率，速率越小，限制流量越小
  - 每次请求，先检查桶里的水量，没有达到最大值，往桶里加水

- 实现方案

  SmoothWarmingUp创建方式：RateLimiter.create(doublepermitsPerSecond, long warmupPeriod, TimeUnit unit)

  permitsPerSecond表示每秒新增的令牌数，warmupPeriod表示在从冷启动速率过渡到平均速率的时间间隔。

  速率是梯形上升速率的，也就是说冷启动时会以一个比较大的速率慢慢到平均速率；然后趋于平均速率（梯形下降到平均速率）。可以通过调节warmupPeriod参数实现一开始就是平滑固定速率。

#### 令牌桶算法（Leaky Bucket）

令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。令牌桶算法的特点是允许突发流量。系统会以一定的速率往桶里添加令牌，处理请求前，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则返回失败。

1. 令牌桶实现点：
   - 所有的请求在处理之前都需要拿到一个可用的令牌才会被处理；
   - 获取不到令牌，则请求返回失败
   - 根据限流大小，设置按照一定的速率往桶里添加令牌；
   - 桶设置最大的放置令牌限制，当桶满时、新添加的令牌就被丢弃或者拒绝；

2. 实现方案

   google开源工具包guava提供了限流工具类RateLimiter，该类基于“令牌桶算法”，非常方便使用。RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率。它支持两种获取permits接口，一种是如果拿不到立刻返回false，一种会阻塞等待一段时间看能不能拿到。平滑突发限流(SmoothBursty)。

~~~java
//多任务执行,但每秒执行不超过2个任务
final RateLimiter rateLimiter = RateLimiter.create(2.0);
void submitTasks(List<Runnable> tasks, Executor executor) {
    for (Runnable task : tasks) {
        rateLimiter.acquire(); // may wait
        executor.execute(task);
    }
}
~~~

~~~java
//以每秒5kb内的速度发送
final RateLimiter rateLimiter = RateLimiter.create(5000.0);
void submitPacket(byte[] packet) {
    rateLimiter.acquire(packet.length);
    networkService.send(packet);
}
~~~

~~~java
//以非阻塞的形式达到降级
if(limiter.tryAcquire()) { //未请求到limiter则立即返回false
    doSomething();
}else{
    doSomethingElse();
}
~~~

以上的方式都是单应用上的请求限流,那么在分布式上，就不能这样全局的方式来实现了。

#### 滑动时间窗口算法

滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。滑动窗口算法是将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期。

1. 滑动窗口算法是以当前这个时间点为基准，往前推移1秒进行计算当前1秒内的请求量情况
2. 滑动窗口限流统计的精准度是由划分的格子多少决定的，这个怎么理解呐，就是把1秒中进行划分成多个时间段，比如2个格子的话，那么就是2段，0-500ms和501-1000ms。那么就会两个值进行存储统计请求量，比如数组[0,1] 各存储一个段的请求值。
3. 计算器算法是滑动窗口算法将时间段划分为1的特殊情况。

https://www.cnblogs.com/mjtabu/p/12603133.html

https://zhuanlan.zhihu.com/p/165006444

### 分布方式的解决方式

1. 纯采用nginx 的IP方式限流,在一些大型的应用流量可以这样控制

   https://www.cnblogs.com/biglittleant/p/8979915.html

2. 采用redis 的计时和计数方式,在规定的时间窗口期,允许通过的最大请求数量

3. 采用redis lua或者 nginx lua方式实现限流处理;

   https://blog.csdn.net/fenglvming/article/details/51996406

一般都是采用应用层的限流,用户接入层都是采用负载均衡去分发流量;

