消息队列中间件有哪些？他们的区别在哪里？

activeMQ、rabbitMq、rocketMq、kafka



### RabbitMQ

#### RabbitMQ的优缺点？

优点：解耦、异步、削峰

缺点：降低了系统的稳定性、可用性（消息队列挂了，看你就用不了），增加了系统的复杂性。

#### 如何保证消息不被重复消费？

​		正常情况下，消费者消费消息时，消费完后会发送一个确认消息给消息队列，消息队列知道消息被消费了，就把这条消息给删除。但是由于网络传输等故障原因，导致确认消息没有送到消息队列，这时候可能重新推送消息给到消费者。

​		消息重复推送不可怕，重要的是要保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；

​		例如：消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；

#### 如何保证消息的可靠性传输？（消息丢失）

- 生产者丢失消息：RabbitMQ提供了transaction和comfirm机制来确保生产者不丢失消息

  事务机制：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。缺点：吞吐量下降；

  confirm模式：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。

- 消息队列丢失消息：

  持久化：

  1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列
  2. 发送消息的时候将deliveryMode=2

- 消费者丢失消息：

  消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！

#### 如何保证消息的有序性？

​		单线程消费保证消息的顺序性；对消息进行编号，消费者处理消息是根据编号处理消息；

#### 如何解决消息队列的延时以及过期失效的问题？消息队列满了以后怎么处理？有几百万消息持续积压几个小时，怎么解决？



#### RabbitMQ怎么进行持久化



#### RabbitMQ实战

- linux安装RabbitMQ

  - 安装Erlang

    ~~~
    wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm
    sudo rpm -Uvh erlang-solutions-1.0-1.noarch.rpm
    sudo yum install erlang
    
     # 启动EPEL源
     sudo yum install epel-release 
     # 安装erlang
     sudo yum install erlang 
    ~~~

  - 安装RabbitMQ

    ~~~
    wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-3.6.15-1.el6.noarch.rpm
    yum install rabbitmq-server-3.6.15-1.el6.noarch.rpm
    #复制配置文件(启动时会到/etc/rabbitmq/读取配置文件)
    cp -r /usr/share/doc/rabbitmq-server-3.6.15/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config
    
    #修改配置文件 （loopback_user）
    vim rabbitmq.config
    
    #启动rabbitmq中插件管理
    rabbitmq-plugins enable rabbitmq_management
    ~~~

    

### Kafka

- 使用场景

  - 构建可在系统或应用程序之间可靠获取数据的实时流数据管道。
  - 构建实时流应用程序，可以转换或响应数据流。

- 特性

  - 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。
  - 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。
  - 支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输。
  - 同时支持离线数据处理和实时数据处理。
  - Scale out：支持在线水平扩展。

- 架构

  - Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker。

  - Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）

  - Partition：Partition是物理上的概念，每个Topic包含一个或多个Partition。

  - Producer：负责发布消息到Kafka broker。

  - Consumer：消息消费者，向Kafka broker读取消息的客户端。

  - Consumer Group:每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group），多个消费者属于同一个消费组，他们是不能重复消费数据的

    **注意点**

    1. 一个Topic的Partition数量大于等于Broker的数量，最好是broker的数量*每一台机器上可用的核数，可以提高吞吐率。
    2. 同一个Partition的Replica尽量分散到不同的机器，最好保存3份，高可用。

- 

- kafka安装

  ~~~
  1.下载kafka_2.12-2.6.0.tgz
  2.上传文件到linux服务器上
  3.tar -zxf kafka_2.11-2.0.0.tgz --解压安装
  4.
  mkdir zdata --创建zookeeper存放数据目录
  mkdir logs --创建kafka日志存放目录
  5.
  cd kafka_2.11-2.0.0/config/ --进入目录
  vim zookeeper.properties --修改配置文件信息
  
  其中：dataDir=/app/kafka/zdata
  
  6.修改kafka配置文件 
    vim server.properties 
  log.dirs=/kafka/logs 
  
  7.kafka启动默认内存不能少于1G:
       配置文件 bin/kafka-server-start.sh 找到export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"  1G , 修改为 : KAFKA_HEAP_OPTS="-Xmx512M -Xms512M",以降低内存要求
       
  8.启动kafka服务
  bin/kafka-server-start.sh config/server.properties
  
  9.创建topic，名为test
  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic test
  
  配置kafka集群：
  	主要修改kafka的server.properties文件
  	
      broker.id=1
      port=9093
      log.dir=/tmp/kafka-logs-
  
  ~~~

  



​		

